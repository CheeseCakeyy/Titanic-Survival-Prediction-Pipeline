
# Titanic Survival Prediction Pipeline

Predicting survival on the Titanic using structured machine learning and principled model evaluation.

---

## ğŸš¢ Project Overview

This project focuses on building a **clean, well-evaluated machine learning pipeline** for the Kaggle *Titanic: Machine Learning from Disaster* competition.  
Rather than leaderboard chasing, the emphasis is on:

- Sound preprocessing
- Feature engineering with intuition
- Proper validation discipline
- Responsible ensembling
- Understanding model behavior and limitations

---

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ feature_creation_titanic_survival.py
â”œâ”€â”€ titanic_survival_prediction_iter(1).py
â”œâ”€â”€ titanic_survival_prediction_iter(2).py
â”œâ”€â”€ titanic_survival_prediction_iter(3).py
â”œâ”€â”€ titanic_survival_prediction_iter(4).py
â”œâ”€â”€ titanic_survival_prediction_iter(5).py
â”œâ”€â”€ Submission1_iter(1).csv
â”œâ”€â”€ Submission1_iter(2).csv
â”œâ”€â”€ Submission1_iter(3).csv
â”œâ”€â”€ Submission1_iter(4).csv
â”œâ”€â”€ Submission1_iter(5).csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

Each iteration represents a **conceptual improvement**, not random tuning.

---

## ğŸ§  Methodology

### 1. Data Preprocessing & Feature Engineering
- Handled missing values using median/mode strategies
- Engineered meaningful features:
  - `Title` (extracted from Name)
  - `Family_size`
  - `Travelling_alone`
- Separate preprocessing pipelines for:
  - Logistic Regression
  - Random Forest / XGBoost
- One-hot encoding for categorical variables
- Scaling applied only where appropriate

---

### 2. Model Iterations

- **Iter 1â€“2:** Baseline Logistic Regression & Random Forest
- **Iter 3â€“4:** Hyperparameter tuning and XGBoost introduction
- **Iter 5:** Final weighted probability ensemble

Models used:
- Logistic Regression
- Random Forest
- XGBoost

---

### 3. Evaluation Strategy

- Stratified train/validation split
- Primary metric: **F1-score**
- Secondary metrics: Accuracy, ROC-AUC
- Ensemble weights derived from **validation performance**
- All model decisions frozen before final evaluation

This avoids leaderboard overfitting and preserves generalization integrity.

---

## ğŸ“Š Results

| Model | Validation F1 |
|------|---------------|
| Logistic Regression | ~0.738 |
| Random Forest | ~0.732 |
| XGBoost | ~0.701 |

The final ensemble slightly outperformed the strongest individual model.

A ~3.6% accuracy improvement resulted in a leaderboard jump from ~12,000 to ~2,000 out of ~14,000 participants.

---

## â­ Key Learnings

- Small datasets can produce misleading validation confidence
- Feature engineering often matters more than model complexity
- Ensembling works best when models have complementary inductive biases
- Knowing **when to stop experimenting** is a critical ML skill

---

## ğŸ§ª How to Run

```bash
git clone https://github.com/CheeseCakeyy/Titanic-Survival-Prediction-Pipeline.git
cd Titanic-Survival-Prediction-Pipeline
pip install -r requirements.txt
python titanic_survival_prediction_iter(5).py
```

---

## ğŸš€ Future Work

- Robust cross-validation (Stratified K-Fold)
- Feature stability analysis
- Model explainability (SHAP)
- Neural networks for learning-based representations

---

## ğŸ“œ License

MIT License
